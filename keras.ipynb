{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32)\n"
     ]
    }
   ],
   "source": [
    "#Everything in keras is a layer or something that is related to layer\n",
    "#A layer is an object that encapsulates weights and some computation(#forward pass)\n",
    "#weights are defined in a build() and computation are defined in a call()\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "class SimpleDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation= None):\n",
    "        super().__init__()\n",
    "        self.units=units\n",
    "        self.activation=activation\n",
    "    \n",
    "    #weight creation takes place in the build() method.\n",
    "    def build(self, input_shape) :\n",
    "        input_dim= input_shape[-1]\n",
    "        #add_weights is an shorcut method for creating weights\n",
    "        self.W=self.add_weight(shape=(input_dim,self.units),initializer=\"random_normal\")\n",
    "        self.b=self.add_weight(shape=(self.units,),initializer=\"zeros\"\n",
    "        )\n",
    "    # we define the forward pass computation in the call method()\n",
    "    def call(self,inputs):\n",
    "        y=tf.matmul(inputs,self.W) + self.b\n",
    "        if self.activation is not None:\n",
    "            y=self.activation(y)\n",
    "        return y\n",
    "\n",
    "my_dense= SimpleDense(units=32,activation=tf.nn.relu) # instantiate our layer, defined previously.\n",
    "input_tensor= tf.ones(shape=(2,784)) # create some test inputs.\n",
    "output_tensor=my_dense(input_tensor) # call the layer on the inputs just like a function.\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dense name=dense_3, built=False>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "#A dense layer with 32 output units\n",
    "layer=layers.Dense(32,activation=\"relu\")\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "models=models.Sequential([layers.Dense(32,activation=\"relu\"),\n",
    "                          layers.Dense(32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "#define alinera classifier\n",
    "model= keras.Sequential([keras.layers.Dense(1)])\n",
    "model.compile(optimizer=\"rmsprop\",loss=\"mean_squared_error\",metrics=[\"accuracy\"])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The fit method implements the training loop itself\n",
    "#1.The Data(inputs and targets)to train on.It is typically passed either in the form of numpy arrays and tensorflow datasets object.\n",
    "#2.The no of epochs to train for:how many times the training loop should iterate over the data passed.\n",
    "#3.The batch size to use within epochs of mini-batch gardient descent\n",
    "import numpy as np;\n",
    "num_samples_per_class=200\n",
    "#The multivariate normal, multinormal is a generalization of the one-dimensionalnormal distribution to  higher dimensions.\n",
    "negative_samples=np.random.multivariate_normal(\n",
    "    mean=[0,3],\n",
    "    cov=[[1,0.5],[0.5,1]],\n",
    "    size=num_samples_per_class\n",
    ")\n",
    "positive_samples=np.random.multivariate_normal(\n",
    "    mean=[3,0],\n",
    "    cov=[[1,0.5],[0.5,1]],\n",
    "    size=num_samples_per_class\n",
    ")\n",
    "inputs=np.vstack((negative_samples,positive_samples)).astype(np.float32)\n",
    "# Create the targets (0 for negative samples, 1 for positive samples)\n",
    "targets = np.vstack((\n",
    "    np.zeros((num_samples_per_class, 1), dtype=\"float32\"),  # Class 0 (negative)\n",
    "    np.ones((num_samples_per_class, 1), dtype=\"float32\")    # Class 1 (positive)\n",
    "))\n",
    "history = model.fit(inputs, targets,epochs=5,batch_size=128)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is using a tool called Keras, which helps us create a machine learning model. \n",
    "# A model is like a very smart machine that learns from data and can make predictions based on what it learned.\n",
    "\n",
    "\n",
    "# Here we are creating a very simple model. Think of the model as a brain that learns from examples. \n",
    "# It has one layer (a \"Dense\" layer) with 1 unit. You can think of a layer like a small part of the brain that helps it learn. \n",
    "# Since there’s only 1 unit, this brain is really simple and is likely used for making a decision between two things (like yes/no or true/false).\n",
    "model=keras.Sequential([keras.layers.Dense(1)])\n",
    "\n",
    "#When we compile the model, we’re telling it how to learn and how to measure how well it’s learning:\n",
    "\n",
    "#Optimizer (RMSprop): This is like the brain's thinking process. It tells the model how to adjust itself to learn better.\n",
    "#The learning rate (0.1) controls how fast it should learn.\n",
    "\n",
    "#Loss (MeanSquaredError): This measures how wrong the model's predictions are during learning. \n",
    "# The goal is to make the error as small as possible.\n",
    "\n",
    "#Metrics-BinaryAccuracy:This checks how many times the model's predictions are correct for two possible answers(like yes/no or 0/1).\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.1),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "#Before we teach the model, we want to mix (shuffle) the examples so that it doesn't learn them in a specific order.\n",
    "# Think of it like mixing flashcards before studying so you don’t memorize the order of answers.\n",
    "#np.random.permutation(len(inputs)): This shuffles the order of the data.\n",
    "#inputs are the examples we give to the model (like questions).\n",
    "#targets are the correct answers to those examples (like the answers to the questions).\n",
    "\n",
    "indices_permutations= np.random.permutation(len(inputs))\n",
    "shuffled_inputs= inputs[indices_permutations]\n",
    "shuffled_targets=targets[indices_permutations]\n",
    "\n",
    "#We split the data into two parts:\n",
    "\n",
    "#Training data (70% of examples): This is the data we use to teach the model.\n",
    "#Validation data (30% of examples): This is used to check how well the model is learning, but we don’t use it for teaching.\n",
    "num_validation_samples= int (0.3 * len(inputs))\n",
    "val_inputs=shuffled_inputs[:num_validation_samples]\n",
    "val_targets=shuffled_targets[:num_validation_samples]\n",
    "training_inputs= shuffled_inputs[num_validation_samples:]\n",
    "training_targets=shuffled_targets[num_validation_samples:]\n",
    "#Now, we’re actually teaching the model using the training data.\n",
    "\n",
    "#Epochs (5): This means the model will go through the entire training data 5 times to learn better.\n",
    "#Batch size (16): This means the model will look at 16 examples at a time while learning.\n",
    "#Validation data: While the model is learning, it checks its progress using the validation data to see how well it's doing.\n",
    "\n",
    "model.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    validation_data=(val_inputs,val_targets)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
