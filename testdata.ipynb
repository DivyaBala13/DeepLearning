{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight (w1): -4.569109499755582\n",
      "Bias (b): 33.585124042691874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Dataset: Pounds in 1000s (x) and MPG (y)\n",
    "X = np.array([3.5, 3.69, 3.44, 3.43, 4.34, 4.42, 2.37]).reshape(-1, 1)\n",
    "y = np.array([18, 15, 18, 16, 15, 14, 24])\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the weight (w1) and bias (b)\n",
    "w1 = model.coef_[0]\n",
    "b = model.intercept_\n",
    "\n",
    "print(f\"Weight (w1): {w1}\")\n",
    "print(f\"Bias (b): {b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the maximum fare? \t\t\t\tAnswer: $159.25\n",
      "What is the mean distance across all trips? \t\t\t\tAnswer: $8.29\n",
      "How many cab companies are in the dataset? \tAnswer: $31.00\n",
      "What is the most frequent payment type? \t\tAnswer: Credit Card\n",
      "Are any features missing data? \t\t\t\tAnswer: No\n",
      "(31694, 6)\n"
     ]
    }
   ],
   "source": [
    "#@title Code - Load dependencies\n",
    "\n",
    "#general\n",
    "import io\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning\n",
    "import keras\n",
    "\n",
    "# data visualization\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "# @title\n",
    "chicago_taxi_dataset = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/chicago_taxi_train.csv\")\n",
    "\n",
    "training_df = chicago_taxi_dataset[['TRIP_MILES', 'TRIP_SECONDS', 'FARE', 'COMPANY', 'PAYMENT_TYPE', 'TIP_RATE']]\n",
    "\n",
    "\n",
    "# What is the maximum fare?\n",
    "max_fare = training_df['FARE'].max()\n",
    "print(\"What is the maximum fare? \\t\\t\\t\\tAnswer: ${fare:.2f}\".format(fare = max_fare))\n",
    "\n",
    "# What is the mean distance across all trips?\n",
    "mean_distance= training_df[\"TRIP_MILES\"].mean()\n",
    "print(\"What is the mean distance across all trips? \\t\\t\\t\\tAnswer: ${mean:.2f}\".format(mean = mean_distance))\n",
    "\n",
    "# How many cab companies are in the dataset?\n",
    "company_no= training_df[\"COMPANY\"].nunique()\n",
    "print(\"How many cab companies are in the dataset? \\tAnswer: ${company:.2f}\".format(company = company_no))\n",
    "training_df.head(200)\n",
    "\n",
    "# What is the most frequent payment type?\n",
    "most_freq_payment_type = training_df['PAYMENT_TYPE'].value_counts().idxmax()\n",
    "print(\"What is the most frequent payment type? \\t\\tAnswer: {type}\".format(type = most_freq_payment_type))\n",
    "\n",
    "# Are any features missing data?\n",
    "missing_values = training_df.isnull().sum().sum()\n",
    "print(\"Are any features missing data? \\t\\t\\t\\tAnswer:\", \"No\" if missing_values == 0 else \"Yes\")\n",
    "\n",
    "#correlation result\n",
    "training_df.corr(numeric_only = True)\n",
    "#Correlation measures the strength and direction of the linear relationship between two variables.\n",
    "# The result is a value between -1 and 1:\n",
    "# A correlation of 1 means a perfect positive relationship.\n",
    "# A correlation of -1 means a perfect negative relationship.\n",
    "# A correlation of 0 means no linear relationship.\n",
    "# For example:\n",
    "\n",
    "# If x1 and x2 have a correlation of 0.8, it indicates that they are positively correlated, meaning that as x1 increases, x2 tends to increase as well.\n",
    "# If x1 and x2 have a correlation of -0.5, it means they are negatively correlated, so as x1 increases, x2 tends to decrease.\n",
    "print(training_df.shape)  # This will give you the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: defining linear regression functions complete.\n",
      "training starting now...\n",
      "INFO: starting training experiment with features=['TRIP_MILES'] and label=FARE\n",
      "\n",
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyaravi/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-09-17 11:23:59.625705: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2024-09-17 11:23:59.625724: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-09-17 11:23:59.625728: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-09-17 11:23:59.625742: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-17 11:23:59.625752: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#@title Code - Define ML functions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def build_model(my_learning_rate, num_features):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "\n",
    "  print(\"Building the model\")\n",
    "  # Most simple keras models are sequential.\n",
    "  model = keras.models.Sequential()\n",
    "\n",
    "  # Describe the topography of the model.\n",
    "  # The topography of a simple linear regression model\n",
    "  # is a single node in a single layer.\n",
    "  model.add(keras.layers.Dense(units=1,\n",
    "                                  input_shape=(num_features,)))\n",
    "\n",
    "  # Compile the model topography into code that Keras can efficiently\n",
    "  # execute. Configure training to minimize the model's mean squared error.\n",
    "  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "  \n",
    "  print(\"Model built\")\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "def train_model(model, df, features, label, epochs, batch_size):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "  print(\"Training the model\")\n",
    "  # Feed the model the feature and the label.\n",
    "  # The model will train for the specified number of epochs.\n",
    "  # input_x = df.iloc[:,1:3].values\n",
    "  # df[feature]\n",
    "  callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "  #Trains the model for a fixed number of epochs (dataset iterations).\n",
    "  history = model.fit(x=features,\n",
    "                      y=label,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=[callback], verbose=True)\n",
    "\n",
    "  # Gather the trained model's weight and bias.\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "\n",
    "  # Isolate the error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  # To track the progression of training, we're going to take a snapshot\n",
    "  # of the model's root mean squared error at each epoch.\n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return trained_weight, trained_bias, epochs, rmse\n",
    "\n",
    "\n",
    "def run_experiment(df, feature_names, label_name, learning_rate, epochs, batch_size):\n",
    "\n",
    "  print('INFO: starting training experiment with features={} and label={}\\n'.format(feature_names, label_name))\n",
    "\n",
    "  num_features = len(feature_names)\n",
    "\n",
    "  features = df.loc[:, feature_names].values\n",
    "  label = df[label_name].values\n",
    "\n",
    "  model = build_model(learning_rate, num_features)\n",
    "  model_output = train_model(model, df, features, label, epochs, batch_size)\n",
    "\n",
    "  print('\\nSUCCESS: training experiment complete\\n')\n",
    "  print('{}'.format(model_info(feature_names, label_name, model_output)))\n",
    "  make_plots(df, feature_names, label_name, model_output)\n",
    "\n",
    "  return model\n",
    "\n",
    "print(\"SUCCESS: defining linear regression functions complete.\")\n",
    "#@title Code - Experiment 1\n",
    "# The following variables are the hyperparameters.\n",
    "\n",
    "training_df = training_df.sample(frac=0.1, random_state=42)  # Use 10% of the data\n",
    "learning_rate = 0.01\n",
    "epochs = 5\n",
    "batch_size = 1\n",
    "\n",
    "# Specify the feature and the label.\n",
    "features = ['TRIP_MILES']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "training_df[features] = scaler.fit_transform(training_df[features])\n",
    "label = 'FARE'\n",
    "print(\"training starting now...\")\n",
    "model_1 = run_experiment(training_df, features, label, learning_rate, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
